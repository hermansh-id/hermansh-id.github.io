---
title: Filo.ai - menguak halusinasi kecerdasan buatan
authors: herman
tags: [AI, Filsafat, Kecerdasan Buatan, Artificial Intelligence]
image: https://miro.medium.com/v2/resize:fit:1100/0*5DVk_pyj1yLxLxWp
hide_table_of_contents: false
---

# Filo.ai: menguak halusinasi kecerdasan buatan

![Photo filo ai](https://miro.medium.com/v2/resize:fit:1100/0*5DVk_pyj1yLxLxWp)
Photo by Kenny Eliason on Unsplash

Kecerdasan buatan telah memberi kesan yang mengagumkan bagi masyarakat kini, sebuah keingininan yang awalnya hanya bisa dilihat dalam film-film fiksi kini mulai terjadi di depan realita. Kini manusia terus bersinggungan dengan teknologi-teknologi kecerdasan buatan, dimulai dari pekerjaan sederhana seperti pengaturan suhu otomatis hingga menulis surat dengan bahasa asing.

Tingkat kontak yang tinggi terhadap kecerdasan buatan memberikan rasa was-was dalam diri manusia, karena seperti biasa manusia akan selalu memberikan kecurigaan pada hal baru yang mulai banyak bersinggungan dengannya. Banyak kecurigaan mengenai kecerdasan buatan ini mulai dari ketakutan mengenai privasi hingga takut kecerdasan buatan akan mengalahkan manusia dan menguasai dunia, sesuatu hal yang biasa kita lihat di film-film fiksi. Tapi apa benar semua itu akan terjadi?

Dalam kasus kecerdasan buatan, mari kita bayangkan seorang bayi lalu kita berikan dia beberapa tugas sederhana padanya, apa yang akan terjadi? Kita contohkan dengan tugas agar bayi dapat memakai bajunya sendiri, apa yang akan dia lakukan pertama adalah ia tidak akan mengerti bagaimana caranya dan kita contohkan dengan memakaikannya baju pada hari-hari awal hingga 1-2 minggu. Itulah yang selanjutnya disebut dengan masa latihan / training pada kasus kecerdasan buatan. Ketika bayi telah dapat memakai bajunya sendiri, dia akan memakai bajunya sendiri namun pada beberapa kesempatan, ia bisa saja tidak fokus dan salah memakai baju sehingga ia memakai baju secara terbalik. hal ini lah yang mungkin dapat terjadi juga pada kecerdasan buatan, dimana kita bisa mengatakan bahwa kecerdasan buatan dapat *berhalusinasi*.

Halusinasi pada kecerdasan buatan adalah keadaan dimana kecerdasan buatan memberikan jawaban yang "sepertinya benar" padahal jawaban yang diberikan adalah sebuah kesalahan. Katakanlah bahwa anda bertanya mengenai "berapa kekayaan elon musk pada tahun 2023?" dan AI menjawab "Â£kekayaan elon musk adalah 400 triliun dollar", jawaban ini sepertinya benar ketika kita tidak melakukan *checking* data sebenarnya. AI dapat memberikan data random pada manusia, atau salah melakukan tugasnya tanpa diketahui kebenarannya oleh manusia. Percayalah, ini lah hal yang paling berbahaya.

Bayangkan anda sebagai seorang direktur memiliki seorang asisten yang anda anggap sangat pintar dan berguna, nama dia adalah jarvis. Jarvis mengerjakan banyak hal, mulai dari memilih menu makan siang, mengatur jadwal hingga ia dapat memberikan tawaran keputusan-keputusan untuk perusahaan anda. Suatu hari, terjadi sebuah masalah pelik dimana anda perlu untuk membuat keputusan bisnis, anda meminta jarvis untuk mengumpulkan data-data terkait kasus ini dan memberikan rangkuman dalam bentuk laporan kepada anda. Anda menerima laporan itu dan membuat keputusan dari laporan tersebut, namun beberapa bulan kemudian perusahaan anda mengalami penurunan performa dan anda disalahkan oleh semua orang. Anda mengevaluasi diri mengapa keputusan anda salah, anda me-*rollback *kembali dan menemukan bahwa keputusan itu berasal dari laporan jarvis, anda memastikan kembali data laporan tersebut dan ternyata ada beberapa data jarvis yang salah sehingga hasil akhir keputusan nya menjadi salah. Jarvis pada hal ini sedang berhalusinasi dengan memberikan data-data salah terkait sebuah kasus dan menghasilkan kesimpulan yang salah. Itulah yang dapat terjadi ketika AI sedang berhalusinasi, seseorang bisa salah dalam mengambil keputusan hanya karena AI berhalusinasi, dan anda bayangkan jika seseorang itu adalah yang memiliki kuasa tinggi maka kesalahan itu akan memberikan kehancuran yang lebih besar.

Apa yang kita takutkan lebih besar lagi jika AI seperti chatGPT ini dipercayai lebih oleh masyarakat rendah, dimana filter terhadap informasi masih belum dilakukan dengan baik. Halusinasi tersebut akan menjadi sumber informasi hoax bagi masyarakat, karena pada dasarnya masyarakat rendah tidak peduli sumbernya dari mana dan bagaimana cara mereka bisa melakukan verifikasi terhadap informasi. Hoax ini bisa juga merambat pada dunia akademik dan profesional, Hoax juga bisa dianggap lumrah dan menjadi fakta sehingga dapat berdampak masif.
